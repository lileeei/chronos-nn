use std::alloc::{GlobalAlloc, Layout, System};
use std::sync::atomic::{AtomicUsize, Ordering};


/// ç®€å•çš„å†…å­˜ä½¿ç”¨è·Ÿè¸ªå™¨
pub struct MemoryTracker {
    allocated: AtomicUsize,
    peak_usage: AtomicUsize,
}

impl MemoryTracker {
    pub const fn new() -> Self {
        Self {
            allocated: AtomicUsize::new(0),
            peak_usage: AtomicUsize::new(0),
        }
    }

    pub fn allocate(&self, size: usize) {
        let current = self.allocated.fetch_add(size, Ordering::Relaxed) + size;
        let mut peak = self.peak_usage.load(Ordering::Relaxed);
        while current > peak {
            match self.peak_usage.compare_exchange_weak(peak, current, Ordering::Relaxed, Ordering::Relaxed) {
                Ok(_) => break,
                Err(x) => peak = x,
            }
        }
    }

    pub fn deallocate(&self, size: usize) {
        self.allocated.fetch_sub(size, Ordering::Relaxed);
    }

    pub fn current_usage(&self) -> usize {
        self.allocated.load(Ordering::Relaxed)
    }

    pub fn peak_usage(&self) -> usize {
        self.peak_usage.load(Ordering::Relaxed)
    }

    pub fn reset(&self) {
        self.allocated.store(0, Ordering::Relaxed);
        self.peak_usage.store(0, Ordering::Relaxed);
    }
}

/// å…¨å±€å†…å­˜è·Ÿè¸ªå™¨å®žä¾‹
static MEMORY_TRACKER: MemoryTracker = MemoryTracker::new();

/// è‡ªå®šä¹‰åˆ†é…å™¨ï¼Œç”¨äºŽè·Ÿè¸ªå†…å­˜ä½¿ç”¨
pub struct TrackingAllocator;

unsafe impl GlobalAlloc for TrackingAllocator {
    unsafe fn alloc(&self, layout: Layout) -> *mut u8 {
        let ptr = unsafe { System.alloc(layout) };
        if !ptr.is_null() {
            MEMORY_TRACKER.allocate(layout.size());
        }
        ptr
    }

    unsafe fn dealloc(&self, ptr: *mut u8, layout: Layout) {
        unsafe { System.dealloc(ptr, layout) };
        MEMORY_TRACKER.deallocate(layout.size());
    }
}

/// å†…å­˜ä½¿ç”¨åˆ†æžç»“æžœ
#[derive(Debug, Clone)]
pub struct MemoryAnalysis {
    pub test_name: String,
    pub initial_memory: usize,
    pub peak_memory: usize,
    pub final_memory: usize,
    pub memory_leaked: usize,
}

impl MemoryAnalysis {
    pub fn memory_increase(&self) -> usize {
        self.peak_memory.saturating_sub(self.initial_memory)
    }

    pub fn print_report(&self) {
        println!("ðŸ“Š å†…å­˜åˆ†æžæŠ¥å‘Š: {}", self.test_name);
        println!("  åˆå§‹å†…å­˜: {} bytes", self.initial_memory);
        println!("  å³°å€¼å†…å­˜: {} bytes", self.peak_memory);
        println!("  æœ€ç»ˆå†…å­˜: {} bytes", self.final_memory);
        println!("  å†…å­˜å¢žé•¿: {} bytes", self.memory_increase());
        if self.memory_leaked > 0 {
            println!("  âš ï¸  å†…å­˜æ³„æ¼: {} bytes", self.memory_leaked);
        }
    }
}

/// å†…å­˜åˆ†æžå™¨
pub struct MemoryProfiler;

impl MemoryProfiler {
    /// åˆ†æžæ•°ç»„å†…å­˜ä½¿ç”¨ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œä½¿ç”¨ä¼°ç®—ï¼‰
    pub fn analyze_array_memory() -> MemoryAnalysis {
        let f64_size = std::mem::size_of::<f64>();

        // ä¼°ç®—ä¸åŒå¤§å°æ•°ç»„çš„å†…å­˜ä½¿ç”¨
        let small_array_size = 1000 * f64_size;
        let medium_array_size = 100 * 100 * f64_size;
        let large_array_size = 10 * 100 * 100 * f64_size;

        let total_estimated = small_array_size + medium_array_size + large_array_size;

        MemoryAnalysis {
            test_name: "Array Memory Usage".to_string(),
            initial_memory: 0,
            peak_memory: total_estimated,
            final_memory: 0,
            memory_leaked: 0,
        }
    }

    /// åˆ†æžRNNå±‚çš„å†…å­˜ä½¿ç”¨ï¼ˆä¼°ç®—ç‰ˆæœ¬ï¼‰
    pub fn analyze_rnn_memory() -> MemoryAnalysis {
        let f64_size = std::mem::size_of::<f64>();

        // ä¼°ç®—RNNå±‚çš„å†…å­˜ä½¿ç”¨
        let input_size = 100;
        let hidden_size = 128;
        let batch_size = 32;
        let seq_len = 50;

        // æƒé‡çŸ©é˜µå†…å­˜
        let weight_memory = (hidden_size * hidden_size + hidden_size * input_size + hidden_size) * f64_size;
        // æ¿€æ´»å€¼å†…å­˜
        let activation_memory = batch_size * seq_len * hidden_size * f64_size;
        // è¾“å…¥æ•°æ®å†…å­˜
        let input_memory = batch_size * seq_len * input_size * f64_size;

        let total_estimated = weight_memory + activation_memory + input_memory;

        MemoryAnalysis {
            test_name: "RNN Layer Memory".to_string(),
            initial_memory: 0,
            peak_memory: total_estimated,
            final_memory: 0,
            memory_leaked: 0,
        }
    }

    /// åˆ†æžLSTMå±‚çš„å†…å­˜ä½¿ç”¨ï¼ˆä¼°ç®—ç‰ˆæœ¬ï¼‰
    pub fn analyze_lstm_memory() -> MemoryAnalysis {
        let f64_size = std::mem::size_of::<f64>();

        // ä¼°ç®—LSTMå±‚çš„å†…å­˜ä½¿ç”¨
        let input_size = 100;
        let hidden_size = 128;
        let batch_size = 32;
        let seq_len = 50;

        // LSTMæœ‰4ä¸ªé—¨ï¼Œæ¯ä¸ªé—¨éƒ½æœ‰æƒé‡çŸ©é˜µ
        let weight_memory = 4 * (hidden_size * (hidden_size + input_size) + hidden_size) * f64_size;
        // æ¿€æ´»å€¼å†…å­˜ï¼ˆéšè—çŠ¶æ€ + ç»†èƒžçŠ¶æ€ï¼‰
        let activation_memory = batch_size * seq_len * hidden_size * 2 * f64_size;
        // è¾“å…¥æ•°æ®å†…å­˜
        let input_memory = batch_size * seq_len * input_size * f64_size;

        let total_estimated = weight_memory + activation_memory + input_memory;

        MemoryAnalysis {
            test_name: "LSTM Layer Memory".to_string(),
            initial_memory: 0,
            peak_memory: total_estimated,
            final_memory: 0,
            memory_leaked: 0,
        }
    }

    /// è¿è¡Œå®Œæ•´çš„å†…å­˜åˆ†æž
    pub fn run_memory_analysis() {
        println!("ðŸ” å¼€å§‹å†…å­˜ä½¿ç”¨åˆ†æž...\n");

        let array_analysis = Self::analyze_array_memory();
        array_analysis.print_report();
        println!();

        let rnn_analysis = Self::analyze_rnn_memory();
        rnn_analysis.print_report();
        println!();

        let lstm_analysis = Self::analyze_lstm_memory();
        lstm_analysis.print_report();
        println!();

        // æ¯”è¾ƒä¸åŒå±‚çš„å†…å­˜æ•ˆçŽ‡
        println!("ðŸ“ˆ å†…å­˜æ•ˆçŽ‡æ¯”è¾ƒ:");
        println!("  RNN å†…å­˜å¢žé•¿: {} bytes", rnn_analysis.memory_increase());
        println!("  LSTM å†…å­˜å¢žé•¿: {} bytes", lstm_analysis.memory_increase());
        
        let efficiency_ratio = if lstm_analysis.memory_increase() > 0 {
            rnn_analysis.memory_increase() as f64 / lstm_analysis.memory_increase() as f64
        } else {
            0.0
        };
        println!("  RNN/LSTM å†…å­˜æ¯”çŽ‡: {:.2}", efficiency_ratio);

        println!();
        MemoryOptimizer::print_optimization_report();
    }
}

/// å†…å­˜ä½¿ç”¨ä¼˜åŒ–å»ºè®®
pub struct MemoryOptimizer;

impl MemoryOptimizer {
    /// ä¼°ç®—æ¨¡åž‹å†…å­˜éœ€æ±‚
    pub fn estimate_model_memory(
        input_size: usize,
        hidden_size: usize,
        seq_len: usize,
        batch_size: usize,
        model_type: &str,
    ) -> usize {
        let f64_size = std::mem::size_of::<f64>();
        
        match model_type {
            "RNN" => {
                // æƒé‡çŸ©é˜µ + åç½® + æ¿€æ´»å€¼
                let weights = (hidden_size * hidden_size + hidden_size * input_size + hidden_size) * f64_size;
                let activations = batch_size * seq_len * hidden_size * f64_size;
                weights + activations
            },
            "LSTM" => {
                // 4ä¸ªé—¨çš„æƒé‡ + åç½® + æ¿€æ´»å€¼ + ç»†èƒžçŠ¶æ€
                let weights = 4 * (hidden_size * (hidden_size + input_size) + hidden_size) * f64_size;
                let activations = batch_size * seq_len * hidden_size * 2 * f64_size; // h + c
                weights + activations
            },
            "GRU" => {
                // 3ä¸ªé—¨çš„æƒé‡ + åç½® + æ¿€æ´»å€¼
                let weights = 3 * (hidden_size * (hidden_size + input_size) + hidden_size) * f64_size;
                let activations = batch_size * seq_len * hidden_size * f64_size;
                weights + activations
            },
            _ => 0,
        }
    }

    /// æä¾›å†…å­˜ä¼˜åŒ–å»ºè®®
    pub fn suggest_optimizations(memory_usage: usize) -> Vec<String> {
        let mut suggestions = Vec::new();

        if memory_usage > 1_000_000_000 { // > 1GB
            suggestions.push("è€ƒè™‘å‡å°‘æ‰¹æ¬¡å¤§å°ä»¥é™ä½Žå†…å­˜ä½¿ç”¨".to_string());
            suggestions.push("ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯ä»£æ›¿å¤§æ‰¹æ¬¡è®­ç»ƒ".to_string());
            suggestions.push("è€ƒè™‘ä½¿ç”¨æ¨¡åž‹å¹¶è¡ŒåŒ–".to_string());
        }

        if memory_usage > 100_000_000 { // > 100MB
            suggestions.push("è€ƒè™‘ä½¿ç”¨æ›´å°çš„éšè—å±‚å¤§å°".to_string());
            suggestions.push("ä½¿ç”¨æˆªæ–­çš„åå‘ä¼ æ’­å‡å°‘åºåˆ—é•¿åº¦".to_string());
        }

        suggestions.push("ä½¿ç”¨in-placeæ“ä½œå‡å°‘ä¸´æ—¶æ•°ç»„åˆ†é…".to_string());
        suggestions.push("è€ƒè™‘ä½¿ç”¨f32è€Œä¸æ˜¯f64ä»¥å‡å°‘å†…å­˜ä½¿ç”¨".to_string());

        suggestions
    }

    /// æ‰“å°å†…å­˜ä¼˜åŒ–æŠ¥å‘Š
    pub fn print_optimization_report() {
        println!("ðŸ› ï¸  å†…å­˜ä¼˜åŒ–å»ºè®®");
        println!("{}", "=".repeat(50));

        // ä¼°ç®—ä¸åŒé…ç½®çš„å†…å­˜ä½¿ç”¨
        let configs = [
            ("å°åž‹RNN", "RNN", 50, 64, 25, 16),
            ("ä¸­åž‹LSTM", "LSTM", 100, 128, 50, 32),
            ("å¤§åž‹LSTM", "LSTM", 200, 256, 100, 64),
        ];

        for (name, model_type, input_size, hidden_size, seq_len, batch_size) in configs {
            let memory = Self::estimate_model_memory(input_size, hidden_size, seq_len, batch_size, model_type);
            println!("{}: ~{:.1} MB", name, memory as f64 / 1_000_000.0);
            
            if memory > 100_000_000 {
                let suggestions = Self::suggest_optimizations(memory);
                for suggestion in suggestions.iter().take(2) {
                    println!("  ðŸ’¡ {}", suggestion);
                }
            }
        }
    }
}
